#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæœåŠ¡ä¸»åº”ç”¨
æä¾›å‘é‡åŒ–ã€æ™ºèƒ½æœç´¢å’ŒAIå¢å¼ºåŠŸèƒ½çš„FastAPIæœåŠ¡
"""

import os
import sys
import time
import logging
from contextlib import asynccontextmanager
from typing import Dict, Any

from fastapi import FastAPI, HTTPException, Depends, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from prometheus_client import start_http_server

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai_service.config import get_settings
from ai_service.database import get_vector_db, close_vector_db
from ai_service.utils.cache import get_cache_manager, close_cache_manager
from ai_service.utils.logging import setup_logging, StructuredLogger
from ai_service.vectorization import get_vectorization_service
from ai_service.search import get_search_service
from ai_service.api import vectorization, search, health

# è®¾ç½®æ—¥å¿—
setup_logging()
logger = logging.getLogger(__name__)

# PrometheusæŒ‡æ ‡
REQUEST_COUNT = Counter(
    'ai_service_requests_total',
    'Total AI service requests',
    ['method', 'endpoint', 'status']
)

REQUEST_DURATION = Histogram(
    'ai_service_request_duration_seconds',
    'AI service request duration',
    ['method', 'endpoint']
)

VECTORIZATION_COUNT = Counter(
    'ai_service_vectorization_total',
    'Total vectorization operations',
    ['model', 'status']
)

SEARCH_COUNT = Counter(
    'ai_service_search_total',
    'Total search operations',
    ['search_type', 'status']
)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ å¯åŠ¨AIæœåŠ¡...")
    
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    settings = get_settings()
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        vector_db = await get_vector_db()
        logger.info("âœ… å‘é‡æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        cache_manager = await get_cache_manager()
        logger.info("âœ… ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–æœåŠ¡
        vectorization_service = get_vectorization_service()
        search_service = get_search_service()
        
        # é¢„çƒ­æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if settings.AI_MODEL_PRELOAD:
            logger.info("ğŸ”¥ é¢„çƒ­AIæ¨¡å‹...")
            try:
                await vectorization_service.preload_models()
                logger.info("âœ… AIæ¨¡å‹é¢„çƒ­å®Œæˆ")
            except Exception as e:
                logger.warning(f"âš ï¸ AIæ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")
        
        # å¯åŠ¨PrometheusæŒ‡æ ‡æœåŠ¡å™¨
        if settings.PROMETHEUS_ENABLED:
            start_http_server(settings.PROMETHEUS_PORT)
            logger.info(f"ğŸ“Š PrometheusæŒ‡æ ‡æœåŠ¡å™¨å¯åŠ¨åœ¨ç«¯å£ {settings.PROMETHEUS_PORT}")
        
        logger.info("ğŸ‰ AIæœåŠ¡å¯åŠ¨å®Œæˆ")
        
        yield
        
    except Exception as e:
        logger.error(f"âŒ AIæœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        raise
    
    # å…³é—­æ—¶æ¸…ç†
    logger.info("ğŸ›‘ å…³é—­AIæœåŠ¡...")
    
    try:
        # å…³é—­æ•°æ®åº“è¿æ¥
        if 'vector_db' in locals():
            await vector_db.close()
            logger.info("âœ… å‘é‡æ•°æ®åº“è¿æ¥å·²å…³é—­")
        
        # å…³é—­ç¼“å­˜ç®¡ç†å™¨
        await close_cache_manager()
        logger.info("âœ… ç¼“å­˜ç®¡ç†å™¨å·²å…³é—­")
        
        logger.info("âœ… AIæœåŠ¡å…³é—­å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ AIæœåŠ¡å…³é—­æ—¶å‡ºé”™: {e}")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="AIæœåŠ¡",
    description="ç³»ç»Ÿè¯„å®¡æŠ€æœ¯å¹³å° - AIå‘é‡åŒ–å’Œæ™ºèƒ½æœç´¢æœåŠ¡",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# è·å–é…ç½®
settings = get_settings()

# æ·»åŠ ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=settings.ALLOWED_HOSTS
)




@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    """è¯·æ±‚æŒ‡æ ‡ä¸­é—´ä»¶"""
    start_time = time.time()
    
    # å¤„ç†è¯·æ±‚
    response = await call_next(request)
    
    # è®°å½•æŒ‡æ ‡
    duration = time.time() - start_time
    method = request.method
    endpoint = request.url.path
    status = str(response.status_code)
    
    REQUEST_COUNT.labels(method=method, endpoint=endpoint, status=status).inc()
    REQUEST_DURATION.labels(method=method, endpoint=endpoint).observe(duration)
    
    return response


@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    """è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶"""
    start_time = time.time()
    
    # è®°å½•è¯·æ±‚
    logger.info(
        f"ğŸ“¥ {request.method} {request.url.path} - "
        f"Client: {request.client.host if request.client else 'unknown'}"
    )
    
    # å¤„ç†è¯·æ±‚
    response = await call_next(request)
    
    # è®°å½•å“åº”
    duration = time.time() - start_time
    logger.info(
        f"ğŸ“¤ {request.method} {request.url.path} - "
        f"Status: {response.status_code} - Duration: {duration:.3f}s"
    )
    
    return response


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTPå¼‚å¸¸å¤„ç†å™¨"""
    logger.warning(
        f"âŒ HTTPå¼‚å¸¸: {exc.status_code} - {exc.detail} - "
        f"Path: {request.url.path}"
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": {
                "code": exc.status_code,
                "message": exc.detail,
                "timestamp": time.time(),
                "path": str(request.url.path)
            }
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """é€šç”¨å¼‚å¸¸å¤„ç†å™¨"""
    logger.error(
        f"ğŸ’¥ æœªå¤„ç†å¼‚å¸¸: {type(exc).__name__}: {str(exc)} - "
        f"Path: {request.url.path}",
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error": {
                "code": 500,
                "message": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯",
                "timestamp": time.time(),
                "path": str(request.url.path)
            }
        }
    )


# æ³¨å†Œè·¯ç”±
app.include_router(health.router, prefix="", tags=["å¥åº·æ£€æŸ¥"])
app.include_router(vectorization.router, prefix="/api/v1/vectorization", tags=["å‘é‡åŒ–"])
app.include_router(search.router, prefix="/api/v1/search", tags=["æ™ºèƒ½æœç´¢"])


@app.get("/metrics")
async def metrics():
    """PrometheusæŒ‡æ ‡ç«¯ç‚¹"""
    from fastapi.responses import Response
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "AIæœåŠ¡",
        "version": "1.0.0",
        "description": "ç³»ç»Ÿè¯„å®¡æŠ€æœ¯å¹³å° - AIå‘é‡åŒ–å’Œæ™ºèƒ½æœç´¢æœåŠ¡",
        "status": "è¿è¡Œä¸­",
        "timestamp": time.time(),
        "endpoints": {
            "health": "/health",
            "docs": "/docs",
            "metrics": "/metrics",
            "vectorization": "/api/v1/vectorization",
            "search": "/api/v1/search"
        }
    }


if __name__ == "__main__":
    import uvicorn
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    host = os.getenv("AI_SERVICE_HOST", "0.0.0.0")
    port = int(os.getenv("AI_SERVICE_PORT", "8001"))
    workers = int(os.getenv("AI_SERVICE_WORKERS", "1"))
    
    logger.info(f"ğŸš€ å¯åŠ¨AIæœåŠ¡åœ¨ {host}:{port}")
    
    uvicorn.run(
        "ai_service.main:app",
        host=host,
        port=port,
        workers=workers,
        reload=settings.DEBUG,
        log_level="info" if not settings.DEBUG else "debug"
    )