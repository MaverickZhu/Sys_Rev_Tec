#!/usr/bin/env python3
"""
AIæœåŠ¡ä¸»åº”ç”¨
æä¾›å‘é‡åŒ–ã€æ™ºèƒ½æœç´¢å’ŒAIå¢å¼ºåŠŸèƒ½çš„FastAPIæœåŠ¡
"""

import logging
import os
import sys
import time
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
from prometheus_client import (
    CONTENT_TYPE_LATEST,
    Counter,
    Histogram,
    generate_latest,
    start_http_server,
)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai_service.api import health, reports, search, vectorization
from ai_service.config import get_settings
from ai_service.database import get_vector_db
from ai_service.reports import get_reports_service
from ai_service.search import get_search_service
from ai_service.utils.cache import close_cache_manager, get_cache_manager
from ai_service.utils.logging import setup_logging
from ai_service.vectorization import get_vectorization_service

# è®¾ç½®æ—¥å¿—
setup_logging()
logger = logging.getLogger(__name__)

# PrometheusæŒ‡æ ‡ - ä½¿ç”¨try/excepté¿å…é‡å¤æ³¨å†Œ
try:
    REQUEST_COUNT = Counter(
        "ai_service_requests_total",
        "Total AI service requests",
        ["method", "endpoint", "status"],
    )

    REQUEST_DURATION = Histogram(
        "ai_service_request_duration_seconds",
        "AI service request duration",
        ["method", "endpoint"],
    )

    VECTORIZATION_COUNT = Counter(
        "ai_service_vectorization_total",
        "Total vectorization operations",
        ["model", "status"],
    )

    SEARCH_COUNT = Counter(
        "ai_service_search_total", "Total search operations", ["search_type", "status"]
    )
except ValueError as e:
    # æŒ‡æ ‡å·²å­˜åœ¨ï¼Œè·å–ç°æœ‰å®ä¾‹
    from prometheus_client import REGISTRY
    REQUEST_COUNT = None
    REQUEST_DURATION = None
    VECTORIZATION_COUNT = None
    SEARCH_COUNT = None
    
    for collector in list(REGISTRY._collector_to_names.keys()):
        if hasattr(collector, '_name'):
            if collector._name == 'ai_service_requests_total':
                REQUEST_COUNT = collector
            elif collector._name == 'ai_service_request_duration_seconds':
                REQUEST_DURATION = collector
            elif collector._name == 'ai_service_vectorization_total':
                VECTORIZATION_COUNT = collector
            elif collector._name == 'ai_service_search_total':
                SEARCH_COUNT = collector


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ å¯åŠ¨AIæœåŠ¡...")

    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    settings = get_settings()

    try:
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        vector_db = await get_vector_db()
        logger.info("âœ… å‘é‡æ•°æ®åº“è¿æ¥æˆåŠŸ")

        # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        cache_manager = await get_cache_manager()
        logger.info("âœ… ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")

        # åˆå§‹åŒ–æœåŠ¡
        vectorization_service = await get_vectorization_service()
        search_service = get_search_service()
        reports_service = await get_reports_service()

        # é¢„çƒ­æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if settings.AI_MODEL_PRELOAD:
            logger.info("ğŸ”¥ é¢„çƒ­AIæ¨¡å‹...")
            try:
                await vectorization_service.preload_models()
                logger.info("âœ… AIæ¨¡å‹é¢„çƒ­å®Œæˆ")
            except Exception as e:
                logger.warning(f"âš ï¸ AIæ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")

        # å¯åŠ¨PrometheusæŒ‡æ ‡æœåŠ¡å™¨
        if settings.PROMETHEUS_ENABLED:
            start_http_server(settings.PROMETHEUS_PORT)
            logger.info(f"ğŸ“Š PrometheusæŒ‡æ ‡æœåŠ¡å™¨å¯åŠ¨åœ¨ç«¯å£ {settings.PROMETHEUS_PORT}")

        logger.info("ğŸ‰ AIæœåŠ¡å¯åŠ¨å®Œæˆ")

        yield

    except Exception as e:
        logger.error(f"âŒ AIæœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        raise

    # å…³é—­æ—¶æ¸…ç†
    logger.info("ğŸ›‘ å…³é—­AIæœåŠ¡...")

    try:
        # å…³é—­æ•°æ®åº“è¿æ¥
        if "vector_db" in locals():
            await vector_db.close()
            logger.info("âœ… å‘é‡æ•°æ®åº“è¿æ¥å·²å…³é—­")

        # å…³é—­ç¼“å­˜ç®¡ç†å™¨
        await close_cache_manager()
        logger.info("âœ… ç¼“å­˜ç®¡ç†å™¨å·²å…³é—­")

        logger.info("âœ… AIæœåŠ¡å…³é—­å®Œæˆ")

    except Exception as e:
        logger.error(f"âŒ AIæœåŠ¡å…³é—­æ—¶å‡ºé”™: {e}")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="AIæœåŠ¡",
    description="ç³»ç»Ÿè¯„å®¡æŠ€æœ¯å¹³å° - AIå‘é‡åŒ–å’Œæ™ºèƒ½æœç´¢æœåŠ¡",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan,
)

# è·å–é…ç½®
settings = get_settings()

# æ·»åŠ ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.add_middleware(TrustedHostMiddleware, allowed_hosts=settings.ALLOWED_HOSTS)


@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    """è¯·æ±‚æŒ‡æ ‡ä¸­é—´ä»¶"""
    start_time = time.time()

    # å¤„ç†è¯·æ±‚
    response = await call_next(request)

    # è®°å½•æŒ‡æ ‡
    duration = time.time() - start_time
    method = request.method
    endpoint = request.url.path
    status = str(response.status_code)

    # æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦å­˜åœ¨
    if REQUEST_COUNT is not None:
        REQUEST_COUNT.labels(method=method, endpoint=endpoint, status=status).inc()
    if REQUEST_DURATION is not None:
        REQUEST_DURATION.labels(method=method, endpoint=endpoint).observe(duration)

    return response


@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    """è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶"""
    start_time = time.time()

    # è®°å½•è¯·æ±‚
    logger.info(
        f"ğŸ“¥ {request.method} {request.url.path} - "
        f"Client: {request.client.host if request.client else 'unknown'}"
    )

    # å¤„ç†è¯·æ±‚
    response = await call_next(request)

    # è®°å½•å“åº”
    duration = time.time() - start_time
    logger.info(
        f"ğŸ“¤ {request.method} {request.url.path} - "
        f"Status: {response.status_code} - Duration: {duration:.3f}s"
    )

    return response


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTPå¼‚å¸¸å¤„ç†å™¨"""
    logger.warning(
        f"âŒ HTTPå¼‚å¸¸: {exc.status_code} - {exc.detail} - Path: {request.url.path}"
    )

    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": {
                "code": exc.status_code,
                "message": exc.detail,
                "timestamp": time.time(),
                "path": str(request.url.path),
            }
        },
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """é€šç”¨å¼‚å¸¸å¤„ç†å™¨"""
    logger.error(
        f"ğŸ’¥ æœªå¤„ç†å¼‚å¸¸: {type(exc).__name__}: {str(exc)} - Path: {request.url.path}",
        exc_info=True,
    )

    return JSONResponse(
        status_code=500,
        content={
            "error": {
                "code": 500,
                "message": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯",
                "timestamp": time.time(),
                "path": str(request.url.path),
            }
        },
    )


# æ³¨å†Œè·¯ç”±
app.include_router(health.router, prefix="", tags=["å¥åº·æ£€æŸ¥"])
app.include_router(
    vectorization.router, prefix="/api/v1/vectorization", tags=["å‘é‡åŒ–"]
)
app.include_router(search.router, prefix="/api/v1/search", tags=["æ™ºèƒ½æœç´¢"])
app.include_router(reports.router, prefix="/api/v1/reports", tags=["æ™ºèƒ½æŠ¥å‘Š"])


@app.get("/metrics")
async def metrics():
    """PrometheusæŒ‡æ ‡ç«¯ç‚¹"""
    from fastapi.responses import Response

    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "AIæœåŠ¡",
        "version": "1.0.0",
        "description": "ç³»ç»Ÿè¯„å®¡æŠ€æœ¯å¹³å° - AIå‘é‡åŒ–å’Œæ™ºèƒ½æœç´¢æœåŠ¡",
        "status": "è¿è¡Œä¸­",
        "timestamp": time.time(),
        "endpoints": {
            "health": "/health",
            "docs": "/docs",
            "metrics": "/metrics",
            "vectorization": "/api/v1/vectorization",
            "search": "/api/v1/search",
            "reports": "/api/v1/reports",
        },
    }


if __name__ == "__main__":
    import uvicorn

    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    host = os.getenv("AI_SERVICE_HOST", "127.0.0.1")  # é»˜è®¤åªç»‘å®šæœ¬åœ°æ¥å£
    port = int(os.getenv("AI_SERVICE_PORT", "8001"))
    workers = int(os.getenv("AI_SERVICE_WORKERS", "1"))

    logger.info(f"ğŸš€ å¯åŠ¨AIæœåŠ¡åœ¨ {host}:{port}")

    uvicorn.run(
        "ai_service.main:app",
        host=host,
        port=port,
        workers=workers,
        reload=settings.DEBUG,
        log_level="info" if not settings.DEBUG else "debug",
    )
