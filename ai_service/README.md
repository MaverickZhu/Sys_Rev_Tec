# AIæœåŠ¡ (AI Service)

æ™ºèƒ½å‘é‡åŒ–å’Œæœç´¢æœåŠ¡ï¼Œä¸ºç³»ç»Ÿè¯„å®¡æŠ€æœ¯å¹³å°æä¾›AIå¢å¼ºåŠŸèƒ½ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
- **æ™ºèƒ½å‘é‡åŒ–**: æ”¯æŒæ–‡æœ¬å’Œæ–‡æ¡£çš„å‘é‡åŒ–å¤„ç†
- **å¤šæ¨¡æ€æœç´¢**: å‘é‡æœç´¢ã€æ–‡æœ¬æœç´¢ã€æ··åˆæœç´¢ã€è¯­ä¹‰æœç´¢
- **é—®ç­”ç³»ç»Ÿ**: åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)çš„æ™ºèƒ½é—®ç­”
- **æ–‡æœ¬å¤„ç†**: æ™ºèƒ½åˆ†å—ã€å…³é”®è¯æå–ã€è¯­è¨€æ£€æµ‹
- **ç¼“å­˜ä¼˜åŒ–**: Redisç¼“å­˜æå‡æ€§èƒ½
- **ç›‘æ§æŒ‡æ ‡**: Prometheusé›†æˆï¼Œå®æ—¶æ€§èƒ½ç›‘æ§

### AIæ¨¡å‹æ”¯æŒ
- **Ollama**: æœ¬åœ°éƒ¨ç½²çš„å¼€æºæ¨¡å‹
- **Azure OpenAI**: äº‘ç«¯GPTæ¨¡å‹
- **è‡ªå®šä¹‰æ¨¡å‹**: æ”¯æŒæ‰©å±•å…¶ä»–AIæœåŠ¡

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### æœ€ä½é…ç½®
- **CPU**: 4æ ¸å¿ƒ
- **å†…å­˜**: 8GB RAM
- **å­˜å‚¨**: 20GBå¯ç”¨ç©ºé—´
- **Python**: 3.11+

### æ¨èé…ç½®
- **CPU**: 8æ ¸å¿ƒ
- **å†…å­˜**: 16GB RAM
- **å­˜å‚¨**: 50GB SSD
- **GPU**: æ”¯æŒCUDAçš„æ˜¾å¡(å¯é€‰)

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šDocker Compose (æ¨è)

1. **å…‹éš†é¡¹ç›®**
```bash
git clone <repository-url>
cd ai_service
```

2. **å¯åŠ¨æœåŠ¡æ ˆ**
```bash
docker-compose up -d
```

3. **ç­‰å¾…æœåŠ¡å¯åŠ¨**
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f ai-service
```

4. **éªŒè¯æœåŠ¡**
```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8001/health

# APIæ–‡æ¡£
open http://localhost:8001/docs
```

### æ–¹å¼äºŒï¼šæœ¬åœ°å¼€å‘

1. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

2. **é…ç½®ç¯å¢ƒå˜é‡**
```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶é…ç½®æ•°æ®åº“å’ŒAIæœåŠ¡
```

3. **å¯åŠ¨ä¾èµ–æœåŠ¡**
```bash
# PostgreSQL
docker run -d --name postgres \
  -e POSTGRES_DB=sys_rev_tec \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=password \
  -p 5432:5432 postgres:15

# Redis
docker run -d --name redis -p 6379:6379 redis:7-alpine

# Ollama
docker run -d --name ollama -p 11434:11434 ollama/ollama:latest
```

4. **å¯åŠ¨AIæœåŠ¡**
```bash
python start_ai_service.py
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

```bash
# æœåŠ¡é…ç½®
AI_SERVICE_HOST=0.0.0.0
AI_SERVICE_PORT=8001

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://postgres:password@localhost:5432/sys_rev_tec

# ç¼“å­˜é…ç½®
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=3600

# AIæ¨¡å‹é…ç½®
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_EMBEDDING_MODEL=nomic-embed-text
VECTOR_DIMENSION=768

# Azure OpenAI (å¯é€‰)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=logs/ai_service.log
```

### Ollamaæ¨¡å‹å®‰è£…

```bash
# å®‰è£…åµŒå…¥æ¨¡å‹
docker exec ollama ollama pull nomic-embed-text

# å®‰è£…å¯¹è¯æ¨¡å‹
docker exec ollama ollama pull llama3.1:8b
docker exec ollama ollama pull qwen2.5:7b

# æŸ¥çœ‹å·²å®‰è£…æ¨¡å‹
docker exec ollama ollama list
```

## ğŸ“š APIæ–‡æ¡£

### å‘é‡åŒ–API

#### ç”Ÿæˆæ–‡æœ¬åµŒå…¥
```bash
POST /api/v1/vectorization/embed
{
  "text": "è¦å‘é‡åŒ–çš„æ–‡æœ¬",
  "provider": "ollama",
  "model": "nomic-embed-text"
}
```

#### æ‰¹é‡å‘é‡åŒ–
```bash
POST /api/v1/vectorization/batch-embed
{
  "texts": ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"],
  "provider": "ollama"
}
```

#### æ–‡æ¡£å‘é‡åŒ–
```bash
POST /api/v1/vectorization/vectorize-document
{
  "content": "æ–‡æ¡£å†…å®¹",
  "document_id": "doc_001",
  "chunk_strategy": "fixed_size",
  "chunk_size": 512
}
```

### æœç´¢API

#### æ™ºèƒ½æœç´¢
```bash
POST /api/v1/search/intelligent
{
  "query": "æœç´¢æŸ¥è¯¢",
  "search_type": "hybrid",
  "limit": 10,
  "filters": {
    "document_type": "pdf",
    "date_range": {
      "start": "2024-01-01",
      "end": "2024-12-31"
    }
  }
}
```

#### é—®ç­”æœç´¢
```bash
POST /api/v1/search/qa
{
  "question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
  "context_limit": 5,
  "generate_answer": true
}
```

### å¥åº·æ£€æŸ¥API

```bash
# åŸºç¡€å¥åº·æ£€æŸ¥
GET /health

# è¯¦ç»†å¥åº·æ£€æŸ¥
GET /health/detailed

# PrometheusæŒ‡æ ‡
GET /health/metrics
```

## ğŸ§ª æµ‹è¯•

### è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/test_ai_service.py -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_ai_service.py::TestVectorizationService -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest tests/test_ai_service.py --cov=ai_service --cov-report=html
```

### æ€§èƒ½æµ‹è¯•
```bash
# å‘é‡åŒ–æ€§èƒ½æµ‹è¯•
python -m ai_service.benchmarks.vectorization_benchmark

# æœç´¢æ€§èƒ½æµ‹è¯•
python -m ai_service.benchmarks.search_benchmark
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### PrometheusæŒ‡æ ‡
- è®¿é—® http://localhost:9090 æŸ¥çœ‹Prometheus
- å…³é”®æŒ‡æ ‡ï¼š
  - `ai_service_requests_total`: è¯·æ±‚æ€»æ•°
  - `ai_service_request_duration_seconds`: è¯·æ±‚è€—æ—¶
  - `ai_service_vectorization_operations_total`: å‘é‡åŒ–æ“ä½œæ•°
  - `ai_service_search_operations_total`: æœç´¢æ“ä½œæ•°

### Grafanaä»ªè¡¨æ¿
- è®¿é—® http://localhost:3000 (admin/admin)
- é¢„é…ç½®ä»ªè¡¨æ¿æ˜¾ç¤ºæœåŠ¡æ€§èƒ½æŒ‡æ ‡

### æ—¥å¿—æŸ¥çœ‹
```bash
# Dockeræ—¥å¿—
docker-compose logs -f ai-service

# æœ¬åœ°æ—¥å¿—
tail -f logs/ai_service.log
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Ollamaè¿æ¥å¤±è´¥**
```bash
# æ£€æŸ¥OllamaçŠ¶æ€
curl http://localhost:11434/api/tags

# é‡å¯Ollama
docker restart ollama
```

2. **æ•°æ®åº“è¿æ¥é”™è¯¯**
```bash
# æ£€æŸ¥PostgreSQLçŠ¶æ€
docker exec postgres pg_isready -U postgres

# æŸ¥çœ‹æ•°æ®åº“æ—¥å¿—
docker logs postgres
```

3. **Redisè¿æ¥é—®é¢˜**
```bash
# æ£€æŸ¥RedisçŠ¶æ€
docker exec redis redis-cli ping

# æŸ¥çœ‹Redisæ—¥å¿—
docker logs redis
```

4. **å†…å­˜ä¸è¶³**
```bash
# æ£€æŸ¥ç³»ç»Ÿèµ„æº
docker stats

# è°ƒæ•´Dockerå†…å­˜é™åˆ¶
# åœ¨docker-compose.ymlä¸­æ·»åŠ :
# deploy:
#   resources:
#     limits:
#       memory: 4G
```

### æ€§èƒ½ä¼˜åŒ–

1. **å‘é‡åŒ–ä¼˜åŒ–**
- ä½¿ç”¨æ‰¹é‡å‘é‡åŒ–å‡å°‘APIè°ƒç”¨
- å¯ç”¨ç¼“å­˜é¿å…é‡å¤è®¡ç®—
- é€‰æ‹©åˆé€‚çš„åˆ†å—å¤§å°

2. **æœç´¢ä¼˜åŒ–**
- ä½¿ç”¨é€‚å½“çš„æœç´¢ç±»å‹
- è®¾ç½®åˆç†çš„ç»“æœé™åˆ¶
- åˆ©ç”¨è¿‡æ»¤å™¨å‡å°‘æœç´¢èŒƒå›´

3. **ç¼“å­˜ä¼˜åŒ–**
- è°ƒæ•´ç¼“å­˜TTL
- ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡
- å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜

## ğŸš€ éƒ¨ç½²æŒ‡å—

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

1. **ç¯å¢ƒå‡†å¤‡**
```bash
# åˆ›å»ºç”Ÿäº§ç¯å¢ƒé…ç½®
cp docker-compose.yml docker-compose.prod.yml

# ç¼–è¾‘ç”Ÿäº§é…ç½®
# - ç§»é™¤ç«¯å£æš´éœ²
# - æ·»åŠ SSLè¯ä¹¦
# - é…ç½®ç¯å¢ƒå˜é‡
# - è®¾ç½®èµ„æºé™åˆ¶
```

2. **SSLé…ç½®**
```bash
# ç”ŸæˆSSLè¯ä¹¦
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout ssl/private.key -out ssl/certificate.crt

# æˆ–ä½¿ç”¨Let's Encrypt
certbot certonly --standalone -d your-domain.com
```

3. **å¯åŠ¨ç”Ÿäº§æœåŠ¡**
```bash
docker-compose -f docker-compose.prod.yml up -d
```

### Kuberneteséƒ¨ç½²

```yaml
# k8s/ai-service-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-service
  template:
    metadata:
      labels:
        app: ai-service
    spec:
      containers:
      - name: ai-service
        image: ai-service:latest
        ports:
        - containerPort: 8001
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: ai-service-secrets
              key: database-url
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€Pull Request

### å¼€å‘è§„èŒƒ
- éµå¾ªPEP 8ä»£ç é£æ ¼
- æ·»åŠ ç±»å‹æ³¨è§£
- ç¼–å†™å•å…ƒæµ‹è¯•
- æ›´æ–°æ–‡æ¡£

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ“ æ”¯æŒ

- ğŸ“§ é‚®ç®±: support@example.com
- ğŸ’¬ è®¨è®º: [GitHub Discussions](https://github.com/your-repo/discussions)
- ğŸ› é—®é¢˜: [GitHub Issues](https://github.com/your-repo/issues)

## ğŸ—ºï¸ è·¯çº¿å›¾

### v1.1 (è®¡åˆ’ä¸­)
- [ ] å¤šè¯­è¨€æ”¯æŒ
- [ ] å›¾åƒå‘é‡åŒ–
- [ ] å®æ—¶æœç´¢
- [ ] æœç´¢ç»“æœæ’åºä¼˜åŒ–

### v1.2 (è®¡åˆ’ä¸­)
- [ ] çŸ¥è¯†å›¾è°±é›†æˆ
- [ ] å¯¹è¯å¼æœç´¢
- [ ] è‡ªåŠ¨æ‘˜è¦ç”Ÿæˆ
- [ ] æœç´¢åˆ†æä»ªè¡¨æ¿

---

**AIæœåŠ¡** - è®©æ™ºèƒ½æœç´¢è§¦æ‰‹å¯åŠ ğŸš€