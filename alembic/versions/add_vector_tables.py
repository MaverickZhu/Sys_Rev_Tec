"""add vector tables

Revision ID: add_vector_tables
Revises: 17a7edcac291
Create Date: 2025-01-27 10:00:00.000000

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'add_vector_tables'
down_revision: Union[str, Sequence[str], None] = '17a7edcac291'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    
    # 创建文档向量表
    op.create_table('document_vectors',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('document_id', sa.Integer(), nullable=False),
        sa.Column('chunk_index', sa.Integer(), nullable=False, comment='文档分块索引'),
        sa.Column('chunk_text', sa.Text(), nullable=False, comment='分块文本内容'),
        sa.Column('chunk_size', sa.Integer(), nullable=True, comment='分块大小'),
        sa.Column('vector_data', sa.JSON(), nullable=True, comment='向量数据(JSON格式)'),
        sa.Column('embedding_model', sa.String(length=100), nullable=True, comment='嵌入模型名称'),
        sa.Column('embedding_dimension', sa.Integer(), nullable=True, comment='向量维度'),
        sa.Column('similarity_threshold', sa.Float(), nullable=True, comment='相似度阈值'),
        sa.Column('metadata', sa.JSON(), nullable=True, comment='元数据'),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.Column('updated_at', sa.DateTime(), nullable=True),
        sa.ForeignKeyConstraint(['document_id'], ['documents.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_document_vectors_document_id'), 'document_vectors', ['document_id'], unique=False)
    op.create_index(op.f('ix_document_vectors_id'), 'document_vectors', ['id'], unique=False)
    op.create_index('ix_document_vectors_chunk_index', 'document_vectors', ['document_id', 'chunk_index'], unique=True)
    
    # 创建向量搜索索引表
    op.create_table('vector_search_indexes',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(length=100), nullable=False, comment='索引名称'),
        sa.Column('description', sa.Text(), nullable=True, comment='索引描述'),
        sa.Column('embedding_model', sa.String(length=100), nullable=False, comment='嵌入模型'),
        sa.Column('dimension', sa.Integer(), nullable=False, comment='向量维度'),
        sa.Column('index_type', sa.String(length=50), nullable=True, comment='索引类型'),
        sa.Column('index_config', sa.JSON(), nullable=True, comment='索引配置'),
        sa.Column('document_count', sa.Integer(), nullable=True, comment='文档数量'),
        sa.Column('vector_count', sa.Integer(), nullable=True, comment='向量数量'),
        sa.Column('is_active', sa.Boolean(), nullable=True, comment='是否激活'),
        sa.Column('last_updated', sa.DateTime(), nullable=True, comment='最后更新时间'),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.Column('updated_at', sa.DateTime(), nullable=True),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_vector_search_indexes_id'), 'vector_search_indexes', ['id'], unique=False)
    op.create_index(op.f('ix_vector_search_indexes_name'), 'vector_search_indexes', ['name'], unique=True)
    
    # 创建搜索查询表
    op.create_table('search_queries',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=True),
        sa.Column('query_text', sa.Text(), nullable=False, comment='查询文本'),
        sa.Column('query_vector', sa.JSON(), nullable=True, comment='查询向量'),
        sa.Column('search_type', sa.String(length=50), nullable=True, comment='搜索类型'),
        sa.Column('filters', sa.JSON(), nullable=True, comment='搜索过滤条件'),
        sa.Column('results_count', sa.Integer(), nullable=True, comment='结果数量'),
        sa.Column('response_time', sa.Float(), nullable=True, comment='响应时间(秒)'),
        sa.Column('similarity_threshold', sa.Float(), nullable=True, comment='相似度阈值'),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='SET NULL'),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_search_queries_id'), 'search_queries', ['id'], unique=False)
    op.create_index(op.f('ix_search_queries_user_id'), 'search_queries', ['user_id'], unique=False)
    op.create_index('ix_search_queries_created_at', 'search_queries', ['created_at'], unique=False)
    
    # 创建知识图谱节点表
    op.create_table('knowledge_graph_nodes',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('entity_id', sa.String(length=100), nullable=False, comment='实体ID'),
        sa.Column('entity_type', sa.String(length=50), nullable=False, comment='实体类型'),
        sa.Column('entity_name', sa.String(length=200), nullable=False, comment='实体名称'),
        sa.Column('description', sa.Text(), nullable=True, comment='实体描述'),
        sa.Column('properties', sa.JSON(), nullable=True, comment='实体属性'),
        sa.Column('source_documents', sa.JSON(), nullable=True, comment='来源文档列表'),
        sa.Column('confidence', sa.Float(), nullable=True, comment='置信度'),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.Column('updated_at', sa.DateTime(), nullable=True),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_knowledge_graph_nodes_entity_id'), 'knowledge_graph_nodes', ['entity_id'], unique=True)
    op.create_index(op.f('ix_knowledge_graph_nodes_entity_type'), 'knowledge_graph_nodes', ['entity_type'], unique=False)
    op.create_index(op.f('ix_knowledge_graph_nodes_id'), 'knowledge_graph_nodes', ['id'], unique=False)
    
    # 创建知识图谱关系表
    op.create_table('knowledge_graph_relations',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('source_entity_id', sa.String(length=100), nullable=False, comment='源实体ID'),
        sa.Column('target_entity_id', sa.String(length=100), nullable=False, comment='目标实体ID'),
        sa.Column('relation_type', sa.String(length=50), nullable=False, comment='关系类型'),
        sa.Column('relation_name', sa.String(length=200), nullable=True, comment='关系名称'),
        sa.Column('properties', sa.JSON(), nullable=True, comment='关系属性'),
        sa.Column('source_documents', sa.JSON(), nullable=True, comment='来源文档列表'),
        sa.Column('confidence', sa.Float(), nullable=True, comment='置信度'),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.Column('updated_at', sa.DateTime(), nullable=True),
        sa.ForeignKeyConstraint(['source_entity_id'], ['knowledge_graph_nodes.entity_id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['target_entity_id'], ['knowledge_graph_nodes.entity_id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_knowledge_graph_relations_id'), 'knowledge_graph_relations', ['id'], unique=False)
    op.create_index('ix_knowledge_graph_relations_source', 'knowledge_graph_relations', ['source_entity_id'], unique=False)
    op.create_index('ix_knowledge_graph_relations_target', 'knowledge_graph_relations', ['target_entity_id'], unique=False)
    op.create_index('ix_knowledge_graph_relations_type', 'knowledge_graph_relations', ['relation_type'], unique=False)
    
    # 为documents表添加AI相关字段
    op.add_column('documents', sa.Column('is_vectorized', sa.Boolean(), nullable=True, comment='是否已向量化'))
    op.add_column('documents', sa.Column('vector_model', sa.String(length=100), nullable=True, comment='向量化模型'))
    op.add_column('documents', sa.Column('embedding_dimension', sa.Integer(), nullable=True, comment='嵌入维度'))
    op.add_column('documents', sa.Column('chunk_count', sa.Integer(), nullable=True, comment='分块数量'))
    op.add_column('documents', sa.Column('vectorized_at', sa.DateTime(), nullable=True, comment='向量化时间'))
    op.add_column('documents', sa.Column('vector_status', sa.String(length=20), nullable=True, comment='向量化状态'))
    op.add_column('documents', sa.Column('ai_summary', sa.Text(), nullable=True, comment='AI生成摘要'))
    op.add_column('documents', sa.Column('ai_keywords', sa.JSON(), nullable=True, comment='AI提取关键词'))
    op.add_column('documents', sa.Column('document_classification', sa.String(length=100), nullable=True, comment='文档分类'))
    op.add_column('documents', sa.Column('risk_assessment', sa.JSON(), nullable=True, comment='风险评估结果'))
    op.add_column('documents', sa.Column('compliance_analysis', sa.JSON(), nullable=True, comment='合规性分析'))
    op.add_column('documents', sa.Column('entity_extraction', sa.JSON(), nullable=True, comment='实体提取结果'))
    
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    
    # 删除documents表的AI相关字段
    op.drop_column('documents', 'entity_extraction')
    op.drop_column('documents', 'compliance_analysis')
    op.drop_column('documents', 'risk_assessment')
    op.drop_column('documents', 'document_classification')
    op.drop_column('documents', 'ai_keywords')
    op.drop_column('documents', 'ai_summary')
    op.drop_column('documents', 'vector_status')
    op.drop_column('documents', 'vectorized_at')
    op.drop_column('documents', 'chunk_count')
    op.drop_column('documents', 'embedding_dimension')
    op.drop_column('documents', 'vector_model')
    op.drop_column('documents', 'is_vectorized')
    
    # 删除知识图谱关系表
    op.drop_index('ix_knowledge_graph_relations_type', table_name='knowledge_graph_relations')
    op.drop_index('ix_knowledge_graph_relations_target', table_name='knowledge_graph_relations')
    op.drop_index('ix_knowledge_graph_relations_source', table_name='knowledge_graph_relations')
    op.drop_index(op.f('ix_knowledge_graph_relations_id'), table_name='knowledge_graph_relations')
    op.drop_table('knowledge_graph_relations')
    
    # 删除知识图谱节点表
    op.drop_index(op.f('ix_knowledge_graph_nodes_id'), table_name='knowledge_graph_nodes')
    op.drop_index(op.f('ix_knowledge_graph_nodes_entity_type'), table_name='knowledge_graph_nodes')
    op.drop_index(op.f('ix_knowledge_graph_nodes_entity_id'), table_name='knowledge_graph_nodes')
    op.drop_table('knowledge_graph_nodes')
    
    # 删除搜索查询表
    op.drop_index('ix_search_queries_created_at', table_name='search_queries')
    op.drop_index(op.f('ix_search_queries_user_id'), table_name='search_queries')
    op.drop_index(op.f('ix_search_queries_id'), table_name='search_queries')
    op.drop_table('search_queries')
    
    # 删除向量搜索索引表
    op.drop_index(op.f('ix_vector_search_indexes_name'), table_name='vector_search_indexes')
    op.drop_index(op.f('ix_vector_search_indexes_id'), table_name='vector_search_indexes')
    op.drop_table('vector_search_indexes')
    
    # 删除文档向量表
    op.drop_index('ix_document_vectors_chunk_index', table_name='document_vectors')
    op.drop_index(op.f('ix_document_vectors_id'), table_name='document_vectors')
    op.drop_index(op.f('ix_document_vectors_document_id'), table_name='document_vectors')
    op.drop_table('document_vectors')
    
    # ### end Alembic commands ###